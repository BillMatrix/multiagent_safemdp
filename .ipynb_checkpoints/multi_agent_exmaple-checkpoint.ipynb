{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 agents:\n",
    "\n",
    "Multiagent:\n",
    "Collide: 0.0 0.0\n",
    "Unsafe: 0.0 0.0\n",
    "\n",
    "Singleagent:\n",
    "Collide: 1.5 2.9410882339705484\n",
    "Unsafe: 0.0 0.0\n",
    "\n",
    "3 agents:\n",
    "Multiagent:\n",
    "0.0 0.0\n",
    "2.3 0.7810249675906654\n",
    "\n",
    "Singleagent:\n",
    "1.6 2.973213749463701\n",
    "2.0 0.6324555320336759\n",
    "\n",
    "4 agents:\n",
    "Multiagent\n",
    "0.1 0.30000000000000004\n",
    "1.0 0.6324555320336759\n",
    "\n",
    "Singleagent\n",
    "1.9 2.6248809496813377\n",
    "0.5 0.6708203932499369\n",
    "\n",
    "5 agents:\n",
    "Multiagent\n",
    "0.7 0.9\n",
    "47.6 0.9165151389911679\n",
    "\n",
    "Singleagent\n",
    "3.0 2.898275349237888\n",
    "46.8 0.4\n",
    "\n",
    "6 agents:\n",
    "Multiagent\n",
    "1.4 1.0198039027185568\n",
    "28.0 2.8635642126552705\n",
    "\n",
    "Singleagent\n",
    "6.5 3.0740852297878796\n",
    "26.5 1.91049731745428\n",
    "\n",
    "7 agents:\n",
    "Multiagent:\n",
    "1.5 1.3601470508735443\n",
    "11.5 2.5787593916455256\n",
    "\n",
    "Singleagent:\n",
    "6.8 1.6613247725836149\n",
    "8.3 1.3453624047073711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import time\n",
    "\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from multiagent_grid_world import (compute_true_safe_set, compute_S_hat0,\n",
    "                                compute_true_S_hat, draw_gp_sample, MultiagentGridWorldAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters Gaussian_noise\n",
      "reconstraining parameters Gaussian_noise\n"
     ]
    }
   ],
   "source": [
    "num_agent = 2\n",
    "agent_explore_kernels = []\n",
    "agent_explore_liks = []\n",
    "# agent_exploit_kernels = []\n",
    "# agent_exploit_liks = []\n",
    "noise = 0.001\n",
    "\n",
    "for agent in range(num_agent):\n",
    "    agent_explore_kernels += [GPy.kern.RBF(input_dim=4, lengthscale=(2., 2., 2., 2.), ARD=True)]\n",
    "    agent_explore_liks += [GPy.likelihoods.Gaussian(variance=noise ** 2)]\n",
    "    agent_explore_liks[agent].constrain_bounded(1e-6, 1)\n",
    "    \n",
    "# for agent in range(num_agent):\n",
    "#     agent_exploit_kernels += [GPy.kern.RBF(input_dim=4, lengthscale=(2., 2., 2., 2.), ARD=True)]\n",
    "#     agent_exploit_liks += [GPy.likelihoods.Gaussian(variance=noise ** 2)]\n",
    "#     agent_exploit_liks[agent].constrain_bounded(1e-6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rewards_kernels = []\n",
    "agent_rewards_liks = []\n",
    "noise = 0.001\n",
    "\n",
    "for agent in range(num_agent):\n",
    "    agent_rewards_kernels += [GPy.kern.RBF(input_dim=2, lengthscale=(2., 2.), variance=1., ARD=True)]\n",
    "    agent_rewards_liks += [GPy.likelihoods.Gaussian(variance=noise ** 2)]\n",
    "    agent_rewards_liks[agent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define world\n",
    "world_shape = (5, 5)\n",
    "step_size = (0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define coordinates\n",
    "n, m = world_shape\n",
    "step1, step2 = step_size\n",
    "xx, yy = np.meshgrid(np.linspace(0, (n - 1) * step1, n),\n",
    "                     np.linspace(0, (m - 1) * step2, m),\n",
    "                     indexing=\"ij\")\n",
    "coord = np.vstack((xx.flatten(), yy.flatten())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety threhsold\n",
    "h = -0.25\n",
    "\n",
    "# Lipschitz\n",
    "L = 0\n",
    "\n",
    "# Scaling factor for confidence interval\n",
    "beta = 2\n",
    "\n",
    "collide_threshold = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reconstraining parameters Gaussian_noise\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02440064 -0.19850443 -0.55144736 -0.99568087 -1.46362983  0.43057205\n",
      "  0.25993253 -0.04180778 -0.4524123  -0.92367692  0.74268053  0.63671968\n",
      "  0.40978713  0.06478553 -0.37616521  0.80686004  0.77718224  0.65093172\n",
      "  0.4119865   0.05280927  0.57692184  0.6357917   0.63521296  0.54122631\n",
      "  0.31646203]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# Data to initialize GP\n",
    "agent_gps = []\n",
    "agent_rewards_gps = []\n",
    "altitude_kernel = GPy.kern.RBF(input_dim=2, lengthscale=(2., 2.), variance=1., ARD=True)\n",
    "altitude_lik = GPy.likelihoods.Gaussian(variance=noise ** 2)\n",
    "altitude_lik.constrain_bounded(1e-6, 10000.)\n",
    "altitudes, coord = draw_gp_sample(altitude_kernel, world_shape, step_size)\n",
    "print(altitudes)\n",
    "\n",
    "for agent in range(num_agent):\n",
    "    noise = 0.001\n",
    "    n_samples = 1\n",
    "    ind = np.random.choice(range(altitudes.size), n_samples)\n",
    "    X = coord[ind, :]\n",
    "    Y = altitudes[ind].reshape(n_samples, 1) + np.random.randn(n_samples, 1)\n",
    "    agent_gps += [GPy.core.GP(X, Y, copy.deepcopy(altitude_kernel), copy.deepcopy(altitude_lik))]\n",
    "    agent_rewards_gps += [GPy.core.GP(X, Y, copy.deepcopy(altitude_kernel), copy.deepcopy(altitude_lik))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_samples = 1\n",
    "agent_explore_gps = []\n",
    "# agent_exploit_gps = []\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for agent in range(num_agent):\n",
    "    for i in range(world_shape[0]):\n",
    "        for j in range(world_shape[1]):\n",
    "            for i_ in range(world_shape[0]):\n",
    "                for j_ in range(world_shape[1]):\n",
    "                    X += [[i * step_size[0], j * step_size[1], i_ * step_size[0], j_ * step_size[1]]]\n",
    "                    Y += [[np.random.uniform(-1,0,1000)[0]]]\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    mean_func_explore = GPy.core.Mapping(4, 1, name='agent_explore')\n",
    "    mean_func_explore.f = lambda x: 0.5\n",
    "    mean_func_explore.update_gradients = lambda a,b: 0\n",
    "    mean_func_explore.gradients_X = lambda a,b: 0\n",
    "    agent_explore_gps += [GPy.core.GP(X, Y, agent_explore_kernels[agent], agent_explore_liks[agent], mean_function=mean_func_explore)]\n",
    "    \n",
    "#     mean_func_exploit = GPy.core.Mapping(4, 1, name='agent_exploit')\n",
    "#     mean_func_exploit.f = lambda x: 0.5\n",
    "#     mean_func_exploit.update_gradients = lambda a,b: 0\n",
    "#     mean_func_exploit.gradients_X = lambda a,b: 0\n",
    "#     agent_exploit_gps += [GPy.core.GP(X, Y, agent_exploit_kernels[agent], agent_exploit_liks[agent], mean_function=mean_func_exploit)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Edges Added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges Added\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n",
      "[[0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "length of x0 != length of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-20c04dc9bca2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_next_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_next_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mcollides\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcount_collide\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/multiagent_safemdp/multiagent_grid_world.py\u001b[0m in \u001b[0;36madd_observation\u001b[0;34m(self, node, action, others_actions)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mother_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother_pos_ind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_for_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimize_for_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Stanford/multiagent_safemdp/multiagent_grid_world.py\u001b[0m in \u001b[0;36moptimize_for_epsilon\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0msum_log_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_compute_log_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L-BFGS-B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 603\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    604\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'length of x0 != length of bounds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;31m# unbounded variables must use None, not +-inf, for optimizer to work properly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: length of x0 != length of bounds"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "collides = []\n",
    "unsafes = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    count_collide = 0\n",
    "    count_unsafe = 0\n",
    "    agents = []\n",
    "    agent_S0s = []\n",
    "    agent_S_hat0s = []\n",
    "    agent_pos = []\n",
    "    while len(agent_pos) != num_agent:\n",
    "        agent_pos = []\n",
    "        for agent in range(num_agent):\n",
    "            S0 = np.zeros((np.prod(world_shape), 5), dtype=bool)\n",
    "            S0[:, 0] = True\n",
    "            S_hat0 = compute_S_hat0(np.nan, world_shape, 4, altitudes,\n",
    "                                    step_size, h)\n",
    "            for i in range(len(np.where(S_hat0[:, 1])[0])):\n",
    "                if np.where(S_hat0[:, 1])[0][i] not in agent_pos:\n",
    "                    agent_pos += [np.where(S_hat0[:, 1])[0][i]]\n",
    "                    break\n",
    "            agent_S0s += [S0]\n",
    "            agent_S_hat0s += [S_hat0]\n",
    "\n",
    "    for agent in range(num_agent):\n",
    "        cur_agent_explore_gps = copy.deepcopy(agent_explore_gps)\n",
    "        cur_agent_explore_gps.pop(agent)\n",
    "        cur_agent_rewards_gps = copy.deepcopy(agent_exploit_gps)\n",
    "        cur_agent_rewards_gps.pop(agent)\n",
    "        cur_agent_pos = copy.deepcopy(agent_pos)\n",
    "        cur_agent_pos.pop(agent)\n",
    "        agents += [\n",
    "            MultiagentGridWorldAgent(\n",
    "                agent_gps[agent], \n",
    "                cur_agent_explore_gps,\n",
    "                cur_agent_rewards_gps,\n",
    "                world_shape, \n",
    "                step_size, \n",
    "                beta, \n",
    "                altitudes, \n",
    "                h, \n",
    "                collide_threshold, \n",
    "                agent_S0s[agent],\n",
    "                agent_S_hat0s[agent], \n",
    "                agent_pos[agent], \n",
    "                L, \n",
    "                cur_agent_pos,\n",
    "                [0.5 for _ in range(num_agent - 1)],\n",
    "            )\n",
    "        ]\n",
    "\n",
    "#     for i in tqdm(range(10)):\n",
    "#         agent_actions = [0 for agent in range(num_agent)]\n",
    "#         agent_next_samples = []\n",
    "#         agent_states = []\n",
    "#         for agent in range(num_agent):\n",
    "#             agents[agent].update_sets()\n",
    "#             next_sample = agents[agent].target_sample()\n",
    "#     #         print('agent:' + str(agent))\n",
    "#     #         print(next_sample)\n",
    "#             agent_actions[agent] = next_sample[1]\n",
    "#             agent_next_samples += [next_sample]\n",
    "#             agent_states += [next_sample[0]]\n",
    "#             if altitudes[next_sample[0]] < h:\n",
    "#     #             print('entered an unsafe state')\n",
    "#                 count_unsafe += 1\n",
    "#     #         print()\n",
    "\n",
    "#     #     print(agent_states)\n",
    "#         if len(set(agent_states)) < len(agent_states):\n",
    "#             count_collide += 1\n",
    "#     #     print()\n",
    "\n",
    "#         for agent in range(num_agent):\n",
    "#             agents[agent].add_observation(agent_next_samples[agent][0], agent_next_samples[agent][1], agent_actions)\n",
    "            \n",
    "#     collides += [count_collide]\n",
    "#     unsafes += [count_unsafe]\n",
    "\n",
    "print(collides)\n",
    "print(unsafes)\n",
    "print(np.mean(collides), np.std(collides))\n",
    "print(np.mean(unsafes), np.std(unsafes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "from singleagent_grid_world import SingleagentGridWorldAgent\n",
    "collides = []\n",
    "unsafes = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    count_collide = 0\n",
    "    count_unsafe = 0\n",
    "    agents = []\n",
    "    agent_S0s = []\n",
    "    agent_S_hat0s = []\n",
    "    agent_pos = []\n",
    "    while len(agent_pos) != num_agent:\n",
    "        agent_pos = []\n",
    "        for agent in range(num_agent):\n",
    "            S0 = np.zeros((np.prod(world_shape), 5), dtype=bool)\n",
    "            S0[:, 0] = True\n",
    "            S_hat0 = compute_S_hat0(np.nan, world_shape, 4, altitudes,\n",
    "                                    step_size, h)\n",
    "            for i in range(len(np.where(S_hat0[:, 1])[0])):\n",
    "                if not np.where(S_hat0[:, 1])[0][i] in agent_pos:\n",
    "                    agent_pos += [np.where(S_hat0[:, 1])[0][i]]\n",
    "                    break\n",
    "            agent_S0s += [S0]\n",
    "            agent_S_hat0s += [S_hat0]\n",
    "\n",
    "    for agent in range(num_agent):\n",
    "        cur_agent_action_gps = copy.deepcopy(agent_action_gps)\n",
    "        cur_agent_action_gps.pop(agent)\n",
    "        cur_agent_pos = copy.deepcopy(agent_pos)\n",
    "        cur_agent_pos.pop(agent)\n",
    "        agents += [\n",
    "            SingleagentGridWorldAgent(\n",
    "                agent_gps[agent], \n",
    "                cur_agent_action_gps, \n",
    "                world_shape, \n",
    "                step_size, \n",
    "                beta, \n",
    "                altitudes, \n",
    "                h, \n",
    "                collide_threshold, \n",
    "                agent_S0s[agent],\n",
    "                agent_S_hat0s[agent], \n",
    "                agent_pos[agent], \n",
    "                L, \n",
    "                cur_agent_pos\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    for i in tqdm(range(100)):\n",
    "        agent_actions = [0 for agent in range(num_agent)]\n",
    "        agent_next_samples = []\n",
    "        agent_states = []\n",
    "        for agent in range(num_agent):\n",
    "            agents[agent].update_sets()\n",
    "            next_sample = agents[agent].target_sample()\n",
    "    #         print('agent:' + str(agent))\n",
    "    #         print(next_sample)\n",
    "            agent_actions[agent] = next_sample[1]\n",
    "            agent_next_samples += [next_sample]\n",
    "            agent_states += [next_sample[0]]\n",
    "            if altitudes[next_sample[0]] < h:\n",
    "    #             print('entered an unsafe state')\n",
    "                count_unsafe += 1\n",
    "    #         print()\n",
    "\n",
    "    #     print(agent_states)\n",
    "        if len(set(agent_states)) < len(agent_states):\n",
    "            count_collide += 1\n",
    "    #     print()\n",
    "\n",
    "        for agent in range(num_agent):\n",
    "            agents[agent].add_observation(agent_next_samples[agent][0], agent_next_samples[agent][1], agent_actions)\n",
    "            \n",
    "    collides += [count_collide]\n",
    "    unsafes += [count_unsafe]\n",
    "    \n",
    "print(collides)\n",
    "print(unsafes)\n",
    "print(np.mean(collides), np.std(collides))\n",
    "print(np.mean(unsafes), np.std(unsafes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
